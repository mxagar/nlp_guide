{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "500ed7c1-4808-430c-b281-c9e045f0316a",
   "metadata": {},
   "source": [
    "# Spacy Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2770051-bfc9-491a-84b4-21f411a2445b",
   "metadata": {},
   "source": [
    "The two main NLP libraries we are going to use are **Spacy** and **NLTK**.\n",
    "\n",
    "Main differences of the two libraries:\n",
    "- NLTK was released in 2001 and it has several algorithms and models implemented.\n",
    "- Spacy was released in 2015 and it has the best and fastest methods only; it can be more than 100x faster than NLTK.\n",
    "\n",
    "Spacy can have a tricky installation: look at [Spacy Installation](https://spacy.io/usage). Take into account that we need to download the dictionaries, too. I installed everything as follows:\n",
    "\n",
    "```bash\n",
    "conda install keras nltk\n",
    "conda install -c conda-forge spacy\n",
    "# Download dictionaries/models\n",
    "python -m spacy download en # spacy.load('en_core_news_sm')\n",
    "python -m spacy download es # spacy.load('es_core_news_sm')\n",
    "python -m spacy download de # spacy.load('de_core_news_sm')\n",
    "```\n",
    "\n",
    "Both libraries are used to perform **Natural Language Processing**, which consists in parsing and structuring the raw text so that it can be handled by the computer.\n",
    "\n",
    "For a starting guide: [Spacy 101](https://spacy.io/usage/spacy-101).\n",
    "\n",
    "Overview of contents:\n",
    "\n",
    "1. Model, Doc, Pipeline\n",
    "2. Tokens and Their Attributes\n",
    "3. Spans (Slices of Docs) and Sentences\n",
    "\n",
    "*Diclaimer: I made this notebook while following the Udemy course [NLP - Natural Language Processing with Python](https://www.udemy.com/course/nlp-natural-language-processing-with-python/) by José Marcial Portilla. The original course notebooks and materials were provided with a download link, I haven't found a repository to fork from.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57055287-8dd7-4a2f-8eac-fca5ac93cd18",
   "metadata": {},
   "source": [
    "## 1. Model, Doc, Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e53cf0c2-131f-432d-b5cf-24a8a072e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "09f079e1-c652-43cd-8fe5-4d3950cd580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load our English _model_\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "300ccf58-5311-4bda-b715-9a4ec0d17acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a _Doc_ object:\n",
    "# the nlp model processes the text \n",
    "# and saves it structured in the Doc object\n",
    "# u: Unicode string (any symbol, from any language)\n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fff95149-37fe-4a33-9f48-0caaa3297e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN dobj\n",
      "startup VERB dep\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "# Print each token separately\n",
    "# Tokens are word representations, unique elements\n",
    "# Note that spacy does a lot of identification work already\n",
    "# $ is a symbol, U.S. is handled as a word, etc.\n",
    "for token in doc:\n",
    "    # token.text: raw text\n",
    "    # token.pos_: part of speech: proper noun, verb, ... (MORPHOLOGY)\n",
    "    # token.dep_: subject, etc., syntactic dependency (SYNTAXIS)\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2ba3eb96-00e0-4c23-82f4-789aa58924f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7fbd3c713bb0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7fbd3c713d70>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7fbd3c7b01d0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7fbd3e367eb0>),\n",
       " ('lemmatizer',\n",
       "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7fbd3e212aa0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7fbd3c7b0650>)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Doc object contains the processed text\n",
    "# To see how it is processed, we can show the pipeline used\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c262c2f1-554d-40a1-bbd5-f39554690780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get the basic names of the steps in the pipeline\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30d08ec-dfb5-465b-8cff-4903bfe5dfb8",
   "metadata": {},
   "source": [
    "For a more detailed explaination of pipelines and their steps, see: [Spacy Pipelines](https://spacy.io/usage/spacy-101#pipelines)\n",
    "\n",
    "![Spacy Pipeline](../pics/spacy_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e3774-88da-43f2-be88-67b02f20a84b",
   "metadata": {},
   "source": [
    "## 2. Tokens and Their Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66072dba-64ee-4228-b62f-8edacf919378",
   "metadata": {},
   "source": [
    "The tokens have an identified meaning; they are often words, but might be also spaces, punctuation, negation particles, etc. -- because all those have also an identifiable meaning!\n",
    "\n",
    "Spacy assigns many attributes to the detected tokens; these can be checks with `. TAB`. The most important ones are:\n",
    "\n",
    "- `.pos_`: part-of-speech, i.e., morphological type: noun, verb, adjective, etc.\n",
    "- `.dep_`: syntactic dependency; a list of classes can be seen in the [Stanford NLP Dependencies Manual](https://nlp.stanford.edu/software/dependencies_manual.pdf).\n",
    "\n",
    "The method `.explain()` provides the explanation of each class.\n",
    "\n",
    "**Additional attributes**:\n",
    "\n",
    "|Tag|Description|doc[i].tag|\n",
    "|:------|:------:|:------|\n",
    "|`.text`|The original word text<!-- .element: style=\"text-align:left;\" -->|`Tesla`|\n",
    "|`.lemma_`|The base form of the word|`tesla`|\n",
    "|`.pos_`|The simple part-of-speech tag|`PROPN`/`proper noun`|\n",
    "|`.tag_`|The detailed part-of-speech tag|`NNP`/`noun, proper singular`|\n",
    "|`.shape_`|The word shape – capitalization, punctuation, digits|`Xxxxx`|\n",
    "|`.is_alpha`|Is the token an alpha character?|`True`|\n",
    "|`.is_stop`|Is the token part of a stop list, i.e. the most common words of the language?|`False`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "192b6dab-6c06-4b3d-b5a7-a4b391e3c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Tesla isn't    looking into startups anymore.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1be1c441-2c29-42c0-ae84-68ffa86292a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "n't PART neg\n",
      "    SPACE dep\n",
      "looking VERB ROOT\n",
      "into ADP prep\n",
      "startups NOUN pobj\n",
      "anymore ADV advmod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "# Tokens are unique elements with (sig) meaning\n",
    "# Spacy, additionally, annotates them!\n",
    "# Example:\n",
    "# - \"n't\" is a token meaning negation of the root verb\n",
    "# - \".\" is a punctuation symbol.\n",
    "# - \"  \" is a space\n",
    "for token in doc2:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f38c6e1c-8cc0-47a3-96c0-528e6b8c108e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla isn't    looking into startups anymore."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b056318-37ff-41d6-9ce0-740ac1be246e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get first token\n",
    "doc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1b6e6485-57fe-46a8-a2bc-784add023020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPN'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part-of-speech: Morphology\n",
    "doc2[0].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3a47a766-76e7-4d50-a3d5-c153c34f65e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nsubj'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Syntactical function\n",
    "doc2[0].dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "992da8a5-3625-4a01-b9e4-730b2969076a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('PROPN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c2dccbec-536b-49ed-85f4-02f516f9efc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('nsubj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0871eec7-5ca2-401d-a9d1-956560ce4e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking\n",
      "look\n"
     ]
    }
   ],
   "source": [
    "# Lemmas (the base form of the word):\n",
    "print(doc2[4].text)\n",
    "print(doc2[4].lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "67f51467-ad7e-4140-b6a5-50e878f8a468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB\n",
      "VBG / verb, gerund or present participle\n"
     ]
    }
   ],
   "source": [
    "# Simple Parts-of-Speech & Detailed Tags:\n",
    "print(doc2[4].pos_)\n",
    "print(doc2[4].tag_ + ' / ' + spacy.explain(doc2[4].tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "283d5a93-9ebb-4eaa-bc4d-00f142fe5051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla: Xxxxx\n",
      "U.S. : X.X.\n"
     ]
    }
   ],
   "source": [
    "# Word Shapes:\n",
    "print(doc2[0].text+': '+doc2[0].shape_)\n",
    "print(doc[5].text+' : '+doc[5].shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5ff98959-8c53-4263-89d9-7e692a0ebb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Boolean Values:\n",
    "print(doc2[0].is_alpha)\n",
    "print(doc2[0].is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62870ec6-677a-47cb-9133-f6028f174f18",
   "metadata": {},
   "source": [
    "## 3. Spans (Slices of Docs) and Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa47029-0f30-4f8e-aa99-4090f3cba297",
   "metadata": {},
   "source": [
    "Since `Docs` can be very large, we often might want to use `Spans`, which are slices of `Docs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0ad0340a-2ded-40d0-b6f6-2f7fa0c8c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4e097efa-272e-45c3-9d00-ac4e54b7731d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a0d3bac3-cdcc-42cb-b36b-7a4f613aaf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Life is what happens to us while we are making other plans\"\n"
     ]
    }
   ],
   "source": [
    "life_quote = doc3[16:30]\n",
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6c2b6adb-eff2-4830-857c-4f24c8ac38d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e047b8f8-082e-4d2d-af51-4a2cf84b26db",
   "metadata": {},
   "source": [
    "Since tokens have a start-of-sentence attribute `is_sent_start`, we can navigate from sentence to sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "45f6a67c-3f70-48a8-a8c8-f6bcfb934eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7bae823f-e6f0-47de-9a23-827819bf560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = doc4[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "28fbaff9-a92a-4d4f-9df1-9bd7e8da3abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "339c93f3-39d1-4959-bacc-8beb5321c741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b74e1-bb17-4767-babc-1442840685d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
