{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42ec922-7779-452e-89b9-c01b4b1cc626",
   "metadata": {},
   "source": [
    "# Vocabulary and Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f6c63-0ed7-48a0-b206-b023ff477f5e",
   "metadata": {},
   "source": [
    "This notebook shows how tokens of groups of tokens can be found/matched in a text. It is equivalent to applying regex, but dictionaries are used instead, making the process more powerful and probably less cryptic.\n",
    "\n",
    "Overview of contents:\n",
    "1. Rule-Based Matching: like regex to find tokens, but with rules defined using dictionaries and pre-defined keys.\n",
    "    - 1.1 Pattern Options and Further Keys\n",
    "2. Phrase Matching: same as before, but applied to group of words (i.e., phrases), not just single tokens.\n",
    "\n",
    "*Diclaimer: I made this notebook while following the Udemy course [NLP - Natural Language Processing with Python](https://www.udemy.com/course/nlp-natural-language-processing-with-python/) by Jos√© Marcial Portilla. The original course notebooks and materials were provided with a download link, I haven't found a repository to fork from.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e10fd-99f5-417f-b241-82be8e1aee65",
   "metadata": {},
   "source": [
    "## 1. Rule-Based Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbacf17-1109-43ed-8bd4-2edd014268e1",
   "metadata": {},
   "source": [
    "Rule-based matching is as a powerful regex; however, instead of using cryptic symbols, dictionaries are defined with pre-defined keys. This kind of matching is used to find tokens of lemmas. Note that it is better to find tokens, since the same token-string can have different lemmas (i.e., depending if the word is noun/verb/adj.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d06f27b2-1090-40b8-8d1e-f143320b9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36961cde-daca-46f3-8519-3139e722fd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library\n",
    "# matcher is an object that pairs to the current Vocab object\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cafc3b5-365b-4540-8512-6c24edcaf77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The phrase 'solar power' might appear\n",
    "# as one word or two, with or without a hyphen.\n",
    "# In this section we'll develop a matcher named 'SolarPower' that finds all three\n",
    "pattern1 = [{'LOWER': 'solarpower'}] # 'solarpower'\n",
    "pattern2 = [{'LOWER': 'solar'}, {'LOWER': 'power'}] # 'solar' 'power'\n",
    "pattern3 = [{'LOWER': 'solar'}, {'IS_PUNCT': True}, {'LOWER': 'power'}] # 'solar' any punctuation (-) 'power'\n",
    "# Key\n",
    "# List of patterns\n",
    "# Callbak: on_match = None\n",
    "matcher.add('SolarPower', [pattern1, pattern2, pattern3], on_match=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0f44f58-4516-4e52-ae4e-f6f5676eb4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'The Solar Power industry continues to grow as demand \\\n",
    "for solarpower increases. Solar-power cars are gaining popularity.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98bf546e-37f6-44ef-93c2-29a87655fa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 10, 11), (8656102463236116519, 13, 16)]\n"
     ]
    }
   ],
   "source": [
    "# List of tuples of matches returned: (match_id, start token pos in Doc, end token pos in Doc)\n",
    "found_matches = matcher(doc)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d67461e8-6c2a-4abf-8fb6-c498d27da2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 SolarPower 1 3 Solar Power\n",
      "8656102463236116519 SolarPower 10 11 solarpower\n",
      "8656102463236116519 SolarPower 13 16 Solar-power\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # get string representation of match_id: matcher Key\n",
    "    span = doc[start:end]                    # get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43372de3-9e73-45f3-b75f-6a5c1179137c",
   "metadata": {},
   "source": [
    "### 1.1 Pattern Options and Further Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66295c5b-8c98-41f7-9df0-1e972a9e01ca",
   "metadata": {},
   "source": [
    "With `OP`, we can pass options to the pattern definitions. For instance: `'OP':'*'` means optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7fb0e82-c498-4a3a-9994-8818ccfecf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the patterns:\n",
    "pattern1 = [{'LOWER': 'solarpower'}] # solarpower\n",
    "pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT': True, 'OP':'*'}, {'LOWER': 'power'}] # solar*power: anything can be *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e2560ed-9c11-42df-84f6-3f235efb7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the old patterns to avoid duplication\n",
    "matcher.remove('SolarPower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abe3b0c2-1718-447c-b55d-71a26ab59c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new set of patterns to the 'SolarPower' matcher\n",
    "matcher.add('SolarPower', [pattern1, pattern2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70cda80f-fbed-4fbb-89b0-1c8180115a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Solar--power is solarpower!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fdece189-1008-40ac-8e08-ae8c346ca035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 0, 3), (8656102463236116519, 4, 5)]\n"
     ]
    }
   ],
   "source": [
    "found_matches = matcher(doc2)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc590227-c06e-4b75-9c56-59de0f2a39fd",
   "metadata": {},
   "source": [
    "The following quantifiers can be passed to the `'OP'` key:\n",
    "\n",
    "<table><tr><th>OP</th><th>Description</th></tr>\n",
    "<tr ><td><span >\\!</span></td><td>Negate the pattern, by requiring it to match exactly 0 times</td></tr>\n",
    "<tr ><td><span >?</span></td><td>Make the pattern optional, by allowing it to match 0 or 1 times</td></tr>\n",
    "<tr ><td><span >\\+</span></td><td>Require the pattern to match 1 or more times</td></tr>\n",
    "<tr ><td><span >\\*</span></td><td>Allow the pattern to match zero or more times</td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426167e5-c474-4746-b601-2d4792617e5c",
   "metadata": {},
   "source": [
    "Besides `LOWER`, `IS_PUNCT` and `OP`, we can pass the following keys to the dictionaries that define the pattern lists:\n",
    "\n",
    "<table><tr><th>Attribute</th><th>Description</th></tr>\n",
    "<tr ><td><span >`LEMMA`</span></td><td>The lemma of a token; be careful: the same token might have different lemmas (e.g., depending if it is a verb/noun/adj.)</td></tr>\n",
    "<tr ><td><span >`ORTH`</span></td><td>The exact verbatim text of a token</td></tr>\n",
    "<tr ><td><span >`LOWER`</span></td><td>The lowercase form of the token text</td></tr>\n",
    "<tr ><td><span >`LENGTH`</span></td><td>The length of the token text</td></tr>\n",
    "<tr ><td><span >`IS_ALPHA`, `IS_ASCII`, `IS_DIGIT`</span></td><td>Token text consists of alphanumeric characters, ASCII characters, digits</td></tr>\n",
    "<tr ><td><span >`IS_LOWER`, `IS_UPPER`, `IS_TITLE`</span></td><td>Token text is in lowercase, uppercase, titlecase</td></tr>\n",
    "<tr ><td><span >`IS_PUNCT`, `IS_SPACE`, `IS_STOP`</span></td><td>Token is punctuation, whitespace, stop word</td></tr>\n",
    "<tr ><td><span >`LIKE_NUM`, `LIKE_URL`, `LIKE_EMAIL`</span></td><td>Token text resembles a number, URL, email</td></tr>\n",
    "<tr ><td><span >`POS`, `TAG`, `DEP`, `LEMMA`, `SHAPE`</span></td><td>The token's simple and extended part-of-speech tag, dependency label, lemma, shape</td></tr>\n",
    "<tr ><td><span >`ENT_TYPE`</span></td><td>The token's entity label</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc1418f-a31a-43c9-b8ff-39498367d068",
   "metadata": {},
   "source": [
    "#### Wildcards: Hashtag Searching Example\n",
    "\n",
    "We can pass an empty dictionary `{}` as a wildcard to represent **any token**. For example, to retrieve hashtags without knowing what might follow the `#` character:\n",
    "\n",
    "```python\n",
    "[{'ORTH': '#'}, {}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6be9b-4e16-402b-9127-cbb0b189cde4",
   "metadata": {},
   "source": [
    "## 2. Phrase Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef19be7-2db8-493f-8680-a10429d514bd",
   "metadata": {},
   "source": [
    "Instead of matching single tokens, we can try to match  groups of words (i.e., phrases). This is more efficient and more commonly done.\n",
    "\n",
    "Text used in this section: [Reaganomics from Wikipedia](https://en.wikipedia.org/wiki/Reaganomics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "01932d31-2778-4616-a5f3-461c1d144f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "665ae44e-d6e4-45e7-9a33-ecb3ec87224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PhraseMatcher library\n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ce80c28d-a04b-490d-9ce1-0478a2235969",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/reaganomics.txt', encoding='cp1252') as f:\n",
    "    doc3 = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "99e85b8f-a7f0-4f1a-b344-65a3044d7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of match phrases\n",
    "phrase_list = ['voodoo economics', 'supply-side economics', 'trickle-down economics', 'free-market economics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5240c09c-6892-4286-a41e-cee14e5b21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each phrase to a Doc object\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f68f4b33-e06d-44c6-a54b-8c5373e2cee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[voodoo economics,\n",
       " supply-side economics,\n",
       " trickle-down economics,\n",
       " free-market economics]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "99b6686e-774b-4fcc-8da3-493337194864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(phrase_patterns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "28d38b76-3b56-4916-81c2-e7b6514bfe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass each Doc object into matcher (note the use of the asterisk!)\n",
    "matcher.add('VoodooEconomics', None, *phrase_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ca4f7275-e041-4dcf-8799-93665424eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of matches\n",
    "matches = matcher(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "67b52793-0068-4496-8a4c-67304640ac39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3473369816841043438, 41, 45),\n",
       " (3473369816841043438, 49, 53),\n",
       " (3473369816841043438, 54, 56),\n",
       " (3473369816841043438, 61, 65),\n",
       " (3473369816841043438, 673, 677),\n",
       " (3473369816841043438, 2987, 2991)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display matches\n",
    "# (match_id, start, end)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f0ab4ee4-8d2f-411e-ad36-a826f59a0bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAGANOMICS\n",
       "https://en.wikipedia.org/wiki/Reaganomics\n",
       "\n",
       "Reaganomics (a portmanteau of [Ronald] Reagan and economics attributed to Paul Harvey)[1] refers to the economic policies promoted by U.S. President Ronald Reagan during the 1980s. These policies are commonly associated with supply-side economics, referred to as trickle-down economics or voodoo economics by political opponents, and free-market economics by political advocates.\n"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first 4 are in the first 70 tokens\n",
    "doc3[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "343ee3f8-ad93-4698-9c92-e4e0cd4b36a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3473369816841043438 VoodooEconomics 41 45 associated with supply-side economics, referred\n",
      "3473369816841043438 VoodooEconomics 49 53 to as trickle-down economics or voodoo\n",
      "3473369816841043438 VoodooEconomics 54 56 economics or voodoo economics by political\n",
      "3473369816841043438 VoodooEconomics 61 65 , and free-market economics by political\n",
      "3473369816841043438 VoodooEconomics 673 677 from the supply-side economics movement,\n",
      "3473369816841043438 VoodooEconomics 2987 2991 as \"trickle-down economics\",\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # get string representation of match_id: matcher Key\n",
    "    span = doc3[start-2:end+2]                    # get the matched span, expanded for context\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1e0b8-5850-463d-9a09-1997b6926099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c784af4-f50c-48d9-bb55-1ef8964d35ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
