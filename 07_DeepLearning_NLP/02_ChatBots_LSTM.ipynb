{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "783a3d44-001b-40b6-8d48-1cd9ac6e3c5c",
   "metadata": {},
   "source": [
    "# Chat Bots with LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d24e11-b9d3-4db2-ad6d-d3c34136886c",
   "metadata": {},
   "source": [
    "This notebook implements a Question-Answer bot which is able to answer questions given a base story. The [BaBi](https://research.facebook.com/downloads/babi/) dataset from Facebook/Meta is used. This dataset is composed with examples consisting of three elemets (Story-Question-Answer), as the following:\n",
    "\n",
    "```\n",
    "1. Story: Jane went to the store. Mike ran to the bedroom.\n",
    "2. Question: Is Mike in the store?\n",
    "3. Answer: No\n",
    "```\n",
    "\n",
    "The built model follows paper by Sukhbaatar et al., linked in the course:\n",
    "\n",
    "`../literature/SukhbaatarFergus_EndToEndMemoryNetworks_2015.pdf`\n",
    "\n",
    "**Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-To-End Memory Networks, 2015.**\n",
    "\n",
    "Note that the implementaton of the model is specific to the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f065ba-dd7f-4690-80de-f05faafcc364",
   "metadata": {},
   "source": [
    "Overview of contents:\n",
    "1. End-To-End Memory Networks, by Sukhbaatar et al., 2015\n",
    "    - Approach\n",
    "    - Model & Training Details\n",
    "    - Simplified Example in the Notebook\n",
    "2. Load and Prepare the Dataset\n",
    "    - 2.1 Understand the Structure of the Dataset\n",
    "    - 2.2 Set Up the Vocabulary\n",
    "    - 2.3 Vectorize the Dataset\n",
    "    - 2.4 Functionalize the Vectorization\n",
    "3. Model\n",
    "    - 3.1 Encoders\n",
    "        - Embedding A / Input Encoder m: `x_i -> m_i`\n",
    "        - Embedding C / Input Encoder c: `x_i -> c_i`\n",
    "        - Embedding B / Input Encoder u: `q -> u`\n",
    "        - Encode the Sequences: `m_i`, `c_i`, `u`\n",
    "    - 3.2 Apply the Encoders and Get Outputs\n",
    "        - Match Probability:  `p_i <- softmax(u^T m_i)`\n",
    "        - Response/Output Vector `o`\n",
    "        - Concatenate: `o + u`\n",
    "    - 3.3 Finalize Model Layers\n",
    "    - 3.4 Training\n",
    "4. Evaluation\n",
    "5. Inference with New Texts: Writing Our Own Stories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c1e2b-0333-45aa-838b-5cba1aa479c3",
   "metadata": {},
   "source": [
    "*Diclaimer: I made this notebook while following the Udemy course [NLP - Natural Language Processing with Python](https://www.udemy.com/course/nlp-natural-language-processing-with-python/) by JosÃ© Marcial Portilla. The original course notebooks and materials were provided with a download link, I haven't found a repository to fork from.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b02e6-a8dc-40a7-ac85-84d3a82b52f1",
   "metadata": {},
   "source": [
    "## 1. End-To-End Memory Networks, by Sukhbaatar et al., 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eef0bf5-0e90-4132-bafe-b3c85d5379e3",
   "metadata": {},
   "source": [
    "Answering questions given context is very challenging, because long-term dependencies need to be addressed in sequential data.\n",
    "\n",
    "Appreaches that use **attention** an **explicit storage** have appeared to solve tackle the problem.\n",
    "\n",
    "The papper presents a RNN in which the recurrence reads from an external memory in multiple hops or computational steps per searched symbol.\n",
    "\n",
    "### Approach\n",
    "\n",
    "The model\n",
    "\n",
    "- takes\n",
    "    - a discrete set of inputs that are store in the memory: `x1, x2, ..., xn`\n",
    "    - a query `q`\n",
    "- outputs: an answer `a`\n",
    "\n",
    "Each of the `x`, `a`, `q` contains symbols that com from a vocabulary/dictionary with `V` words. I understand that `x` is a collection of sequences, while `q` and `a` are supposed to be one sequence each.\n",
    "\n",
    "The model writes all `x` to the memory up to a fixed buffer size and then finds a continuous representation for the `x` and `q` (using embeddings). Then, those continuous representations are processed in several steps/hops to obtain `a`.\n",
    "\n",
    "Each layer has the following components:\n",
    "- The input memory where all sentences/sequences `x` and `q` are stored encoded in an embedding A.\n",
    "- The ouput memory where all sentences/sequences `x` are stored encoded in an embedding C; this memory contains the seed elements that, together with `q`, lead to an answer `a`.\n",
    "- The generator of the final prediction of the layer, which combines the items in both.\n",
    "\n",
    "Then, these single layers are combined as recurrent layers that perform several hops or steps to obtain the final output.\n",
    "\n",
    "A single layer consists of the following operations, and it is depicted in the figure below:\n",
    "\n",
    "- given `x_i`, we compute in th einput memory: `m_i <- EmbeddingA(x_i)`\n",
    "- we store the vector `m_i` in the input memory\n",
    "- given `q`, we compute: `u <- EmbeddingB(q)`\n",
    "- we store the vector `u` in the input memory\n",
    "- we computethe match weight/probability `p_i` as: `p_i = softmax(u^T * m_i)` (inner product)\n",
    "- given `x_i`, we compute in the output memory: `c_i <- EmbeddingC(x_i)`\n",
    "- the output/response vector `o` is the sum of `c_i` weighted by `p_i`: `o <- sum(p_i*c_i)`\n",
    "- the predicted answer `a` is: `a <- softmax(W(o+u))`\n",
    "    - `W` is a weight matrix of size `V x d`\n",
    "    - `V`: number of symbols/tokens in the vocabulary/dictionary\n",
    "    - `d`: size of the compact sequence vectors in the embedding\n",
    "    \n",
    "Note that everything is differentiable. That makes possible to use backpropagation, i.e., we can train the layers to optimize the weights of `W`.\n",
    "\n",
    "![End-To-End memory Networks](../pics/end_to_end_memory_networks.png)\n",
    "\n",
    "The recurrent aspect is achieved by stacking one layer after the other. All layers get all sentences of the story `x` and the same question `q`, but the output from the previous layer is summed to the question in the next layer.\n",
    "\n",
    "### Model & Training Details\n",
    "\n",
    "- `K = 3` hops/steps or layers were used.\n",
    "- Tyically, the answr is a single words, but sometimes several.\n",
    "- Some sentences in the story are irrelevant for the answer; the relevant ones are called **support** and the model detects them.\n",
    "- The sentences are represented initially as bags of words; each sentence `x_i` in a story is transformed in `m_i` by summing all the vector representations of all words after applying the embedding.\n",
    "- In order to preserve the order aspect of the words in a sentence and the temporal aspect of the sentences in a story, some weights/encoding are applied element-wise to the summations.\n",
    "- They found that adding random noise to the temporal encoding improved the performance.\n",
    "- Learning rate: `lr = 0.01`, annealing to `lr/2` every 25 epochs until 100 epochs were reached.\n",
    "- The `null` symbol was used for padding.\n",
    "\n",
    "### Simplified Example in the Notebook\n",
    "\n",
    "The example in this notebook uses a very similar approach, but the dataset consists of Story-Question-Answer items that have only `Yes/No` answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808f6dd2-2957-44a5-9fc9-341d72a556d0",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f50a5aad-3029-41d2-b2ae-59696414d35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ceefc3ba-e308-4f40-afd9-08e6ea51d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch out: the TXT is a binary, thus we need to use pickle to read it\n",
    "with open(\"../data/train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef6ab893-7f95-49fd-a3c6-cefc61963760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch out: the TXT is a binary, thus we need to use pickle to read it\n",
    "with open(\"../data/test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6563fdca-28db-4135-8700-f3fcc23bab2e",
   "metadata": {},
   "source": [
    "### 2.1 Understand the Structure of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "946236c4-53d8-4ffe-8e5b-7c9ac5df5b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d7483a2-13ca-4145-be3d-c21a1241a4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10,000 items for the training data\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e94dfc2-5b63-4efb-b197-630754cd3a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick and display one item: Story, Question, Answer.\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6b662b3-b799-4577-9d90-a11abb07de1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the Story\n",
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef4c4b53-5d47-4eb1-8220-04836645b02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the Question\n",
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd2f6118-bb06-4227-9065-7db907f9b0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the Answer: IT IS ALWAYS YES/NO!\n",
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742a8eee-5ff1-4196-a700-25d7a379ba79",
   "metadata": {},
   "source": [
    "### 2.2 Set Up the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99e469ca-cef7-4b40-84ed-3ab91c12e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "# Set: unordered collection of unique items\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3743fed2-0eef-45e5-a0b7-3674b6c2823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate both splits\n",
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c2071906-dd09-49dd-9849-961d574e4875",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    # Basically, a union is done: all distinct items are taken to create a new set.\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c4a46694-ada5-4f11-b4a1-b4318a6ad266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the Answer is always Yes/No, we add these words manually\n",
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61a17b16-2af5-4b0f-9489-49f58a7a9caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all possible vocabulary words.\n",
    "# Note that they are not that much.\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7bd1af57-a1f8-40b0-91ff-889ff0276666",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 # we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "14d91f75-c26e-4331-81fc-80e556db5268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1f5d57e6-89fe-4a4a-a968-3796c4e94c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How long is the longest Story?\n",
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5850ceb-d43f-44ad-a045-0c62a114d611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc943d7e-0be4-4bf4-af3a-ac82a0b0d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How long is the longest Question?\n",
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af5965fa-755c-4155-ad84-7a0f26dc7c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21810d9-0de1-4a0a-b5df-323b152bf774",
   "metadata": {},
   "source": [
    "### 2.3 Vectorize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50917b37-9df6-48c2-b086-ce528edb9159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bcb55095-bbaa-46c3-96a7-da0693d2b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer encoded sequences of words\n",
    "# We don't need to use any filters with our dataset\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c374ba0e-2df6-4413-8b15-0ad9a2b284c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 1,\n",
       " 'no': 2,\n",
       " '?': 3,\n",
       " 'yes': 4,\n",
       " 'bathroom': 5,\n",
       " 'grabbed': 6,\n",
       " 'down': 7,\n",
       " '.': 8,\n",
       " 'hallway': 9,\n",
       " 'bedroom': 10,\n",
       " 'kitchen': 11,\n",
       " 'dropped': 12,\n",
       " 'is': 13,\n",
       " 'mary': 14,\n",
       " 'picked': 15,\n",
       " 'daniel': 16,\n",
       " 'garden': 17,\n",
       " 'left': 18,\n",
       " 'there': 19,\n",
       " 'moved': 20,\n",
       " 'to': 21,\n",
       " 'office': 22,\n",
       " 'sandra': 23,\n",
       " 'milk': 24,\n",
       " 'discarded': 25,\n",
       " 'journeyed': 26,\n",
       " 'in': 27,\n",
       " 'back': 28,\n",
       " 'up': 29,\n",
       " 'john': 30,\n",
       " 'got': 31,\n",
       " 'took': 32,\n",
       " 'football': 33,\n",
       " 'went': 34,\n",
       " 'travelled': 35,\n",
       " 'the': 36,\n",
       " 'put': 37}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary/Map of word->index\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "25af2961-3080-445b-be7d-8ac723ce417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack Story/Question/Answer to lists\n",
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1667a932-5637-463f-9906-ea1e04e17f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text/string sequences to integer sequences\n",
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea1e0242-7908-49ea-b391-36e207072b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bathroom',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'journeyed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f04b1ddd-dfc0-4611-a337-e5502206a554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 20, 21, 36, 5, 8, 23, 26, 21, 36, 10, 8]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "670469e5-c78e-4ea4-92f8-ae4b9c55c230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9870dd52-39df-48ea-aa6d-eac3277995e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4a5cc-7e7d-494b-8e1d-e3dbdc7d6740",
   "metadata": {},
   "source": [
    "### 2.4 Functionalize the Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f0f902-b849-457d-921c-277b33bfb94b",
   "metadata": {},
   "source": [
    "In the following, we create a function that creates valid input vectors of a dataset. Basically, S-Q-A texts are converted into integer/word-index matrices. Note that the answers are allowed to have the same dimension as the size of the vocabulary (`+1`, because of Keras convention). I understand that the logic is the following: originally, an answer of a single word was allowed, no matter which word in the vocabulary; thus, the answer is a dummy/one-hot endoded vectors. In the present simplified implementation, that same architecture/design is used, but through the dataset and its training, only the words `yes`/`no` appear in the answers. Thus, I could easily modify this example to get any single word as answer (one word from the vocabulary) -- only, I would require a valid dataset with any single word as answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "467a5fc2-acbf-4f0f-aae1-5356e7c290e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data,\n",
    "                      word_index=tokenizer.word_index,\n",
    "                      max_story_len=max_story_len,\n",
    "                      max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories, Queries, and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories, questions, and answers into padded sequences.\n",
    "    We first loop for every story, query, and answer in the data.\n",
    "    Then we convert the raw words to an word index value.\n",
    "    Then we append each set to their appropriate output list.\n",
    "    Then, once we have converted the words to numbers,\n",
    "    we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X, Xq, Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER (yes/no)\n",
    "    Y = []\n",
    "    \n",
    "    # For each Story-Question-Answer\n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        # We create an array of size the number of vocabulary items\n",
    "        #y = np.zeros(len(word_index) + 1)\n",
    "        y = np.zeros(vocab_len)\n",
    "        \n",
    "        # Now that y is all zeros and we know it's just Yes/No,\n",
    "        # we can use numpy logic to create this assignment\n",
    "        # Everything is 0 except the answer word (yes/no)\n",
    "        # Why? In understand that originally the answer is supposed to be one word\n",
    "        # not just yes/no. Thus, here the architecture/structure is maintained,\n",
    "        # but the model is trained only with yes/no.\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story, query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),\n",
    "            pad_sequences(Xq, maxlen=max_question_len),\n",
    "            np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "11d889dc-fc5a-43de-9b2d-5e54b99d5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5a394f34-f1b5-4828-8908-bf802a030a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f82884b3-a55c-4de9-a21f-fe084bb45fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 156)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of S-Q-A items x max_story_len (maximum number of words in a story)\n",
    "inputs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ce421b16-a9c1-4622-88b6-ba01aedccd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 36, 10,  8],\n",
       "       [ 0,  0,  0, ..., 36, 17,  8],\n",
       "       [ 0,  0,  0, ..., 36, 17,  8],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 36,  1,  8],\n",
       "       [ 0,  0,  0, ..., 36, 17,  8],\n",
       "       [ 0,  0,  0, ...,  1, 19,  8]], dtype=int32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "de2b6008-2d3a-462f-967c-bebda0bbc766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of S-Q-A items x max_question_len (maximum number of words in a story)\n",
    "queries_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "056aba2f-88d4-48b7-9b45-ba95406db76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 30, 27, 36, 11,  3],\n",
       "       [13, 30, 27, 36, 11,  3],\n",
       "       [13, 30, 27, 36, 17,  3],\n",
       "       ...,\n",
       "       [13, 14, 27, 36, 10,  3],\n",
       "       [13, 23, 27, 36, 17,  3],\n",
       "       [13, 14, 27, 36, 17,  3]], dtype=int32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f3e174d7-4afd-4a47-8a64-86b406718e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 38)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of S-Q-A items x (vocabulary length + 1)\n",
    "answers_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f8d9e7a9-33ee-4804-8c2e-ec6780853fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2bbe7a7a-1e5c-4420-8ec5-b71915aed778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0., 503.,   0., 497.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All answers must be yes (index 4) or no (index 2)\n",
    "# Thus, the sum must be concentrated in those two elements/indices\n",
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d1796402-ccfb-46e5-8558-6e0a83cfc67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bf434dd9-74bb-4d5a-b78c-6be0b3f39e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fefd1ba-a170-40db-840a-6dfbe03314da",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6650871f-a954-4885-b133-a90d8d017e63",
   "metadata": {},
   "source": [
    "In this section, the DL model that predicts answers given a story and a question is built. The model is strongly based on the one suggested in the paper by Sukhbaatar et al. referenced above. Read the paper or the notes to understand the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b19f8dbe-4f3d-4f2f-ba01-69f76d65c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "38e311ac-dd46-43f8-b3e0-b226ca5b476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input() is used to instantiate Keras tensors\n",
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7df490-8074-4e94-8da5-e1f84a836771",
   "metadata": {},
   "source": [
    "### 3.1 Encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ffef6-c8ac-4637-b7d7-a4fb81c45b2b",
   "metadata": {},
   "source": [
    "#### Embedding A / Input Encoder m: `x_i -> m_i`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "53d9ea92-2eb2-4d7e-9273-7e553cc16ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_len\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "431d2482-77f0-47ff-b3ce-32ef472994d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "# We add a dropout of 30% to prevent overfitting\n",
    "input_encoder_m.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123d92d4-e668-4d53-b547-d15e9113c44d",
   "metadata": {},
   "source": [
    "#### Embedding C / Input Encoder c: `x_i -> c_i`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bca6d00d-5961-4482-9cac-d7b4bea4ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the input into a sequence of vectors of size query_maxlen\n",
    "# Output: (samples, story_maxlen, max_question_len)\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64626305-a5b2-4a9c-a9bc-4511f2d853b3",
   "metadata": {},
   "source": [
    "#### Embedding B / Input Encoder u: `q -> u`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7a4f0aa1-85d1-4092-88e8-7a69dafa74f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the question into a sequence of vectors\n",
    "# Output: (samples, query_maxlen, embedding_dim)\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819738d8-f506-44ae-a7c5-cc1f37e879f7",
   "metadata": {},
   "source": [
    "#### Encode the Sequences: `m_i`, `c_i`, `u`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fa59174e-ac0d-44e9-9c96-666e21e192af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors.\n",
    "# We basically apply the encoers/embeddings defined until now (above).\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac576d7-9d53-483f-b888-e3b510c87625",
   "metadata": {},
   "source": [
    "### 3.2 Apply the Encoders and Get Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d241c0-4a84-4857-aaed-d079e68b305c",
   "metadata": {},
   "source": [
    "#### Match Probability:  `p_i <- softmax(u^T m_i)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "36bee4ac-74da-40e6-9e9d-cd3490e1e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot-product between u and m_i\n",
    "# Shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25befd4d-6eb9-441f-ad6b-8cc753d62259",
   "metadata": {},
   "source": [
    "#### Response/Output Vector `o`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "77d53970-e712-44ee-90ab-3c2ae1af23dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, max_question_len)\n",
    "# Switch 2 dimensions\n",
    "response = Permute((2, 1))(response)  # (samples, max_question_len, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8b825d-e5e6-409a-a1de-3b436f27a250",
   "metadata": {},
   "source": [
    "#### Concatenate: `o + u`\n",
    "\n",
    "Why concatenate? I though we add them. That's what seems to be written in the paper, too...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7d19b2a6-d57f-49d0-a42c-525fee680ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7a9cdbba-1216-4e67-abb6-a95727a69955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_3/concat:0' shape=(None, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape: ?, 6, 220\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4f1b0-5b6d-4094-80be-a47c0645a619",
   "metadata": {},
   "source": [
    "### 3.3 Finalize Model Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c8d9d-8207-4cdc-bb48-be5d1889ac88",
   "metadata": {},
   "source": [
    "I don't understand why he does this. where are the `K=3` hops?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c433728b-2ff2-474c-bba3-0fa19d75506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM) ???\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0fa83d85-2623-43b1-9e90-b097bc5547cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "# Although only yes/no is expected expected (because the training dataset has only yes/no)\n",
    "# we allow the probabilities to be associated t o each of the words in the vocabulary\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b2bfbb87-abd3-42bf-9b6f-109cd8a59336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# Build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ba4cd949-0da3-4de9-b194-8bc746010ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 156, 6)       0           sequential_5[2][0]               \n",
      "                                                                 sequential_8[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 156, 6)       0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 156, 6)       0           activation_2[0][0]               \n",
      "                                                                 sequential_7[3][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 6, 156)       0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 6, 220)       0           permute_4[0][0]                  \n",
      "                                                                 sequential_8[3][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 32)           32384       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32)           0           lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 38)           1254        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 38)           0           dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec67d6f9-f6f4-413d-8150-4a3d24507414",
   "metadata": {},
   "source": [
    "### 3.4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c55a71e6-9bb2-4d4d-8b09-d42dac578b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2699 - accuracy: 0.8797 - val_loss: 0.3637 - val_accuracy: 0.8370\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.2742 - accuracy: 0.8787 - val_loss: 0.3786 - val_accuracy: 0.8250\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.2752 - accuracy: 0.8792 - val_loss: 0.3613 - val_accuracy: 0.8350\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2717 - accuracy: 0.8794 - val_loss: 0.3704 - val_accuracy: 0.8340\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2689 - accuracy: 0.8830 - val_loss: 0.3643 - val_accuracy: 0.8360\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2668 - accuracy: 0.8835 - val_loss: 0.3588 - val_accuracy: 0.8390\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2634 - accuracy: 0.8818 - val_loss: 0.3774 - val_accuracy: 0.8330\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2624 - accuracy: 0.8842 - val_loss: 0.3756 - val_accuracy: 0.8360\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2590 - accuracy: 0.8851 - val_loss: 0.3724 - val_accuracy: 0.8380\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2593 - accuracy: 0.8875 - val_loss: 0.4045 - val_accuracy: 0.8280\n"
     ]
    }
   ],
   "source": [
    "# We should train for at least 120 epochs!\n",
    "history = model.fit([inputs_train, queries_train],\n",
    "                    answers_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=10,\n",
    "                    validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7b10ad3f-ed06-4612-a21a-90cd26264547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "filename = 'chatbot_60_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ac1de-b2c9-4b3a-a44d-e33ccaa6b284",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b4655939-e039-4a47-8a94-c07fa47a410d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy plotting\n",
    "# Note that the plot below is maybe not accurate, since I would need to let it train longer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "43a456eb-1d01-4238-a6b6-4fe575b98a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of using our trained model\n",
    "# we load the weights of a moddel provvided in teh course\n",
    "#filename = 'chatbot_120_epochs.h5'\n",
    "filename = 'chatbot_60_epochs.h5'\n",
    "model.load_weights(filename)\n",
    "# And predict the answers of the test split\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "210e2add-247c-4af4-878f-29f8698db68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "869ee116-f481-4d71-839f-f6942c6cd903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "906c4226-a6bc-4b7e-aa3c-8cafaf96bd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0fef865c-a703-461b-b53d-a148dc0d16f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2733a848-974b-4b87-9211-7760765ee5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.99932635\n"
     ]
    }
   ],
   "source": [
    "# Generate prediction from model\n",
    "# In my case it seems to perform poorly - it is not even able to provide just yes/no\n",
    "# BUT that is maybe because the tokenizer is different now...\n",
    "# With my trained model it seems to work...\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71816bed-d244-475b-b560-e98ba651e931",
   "metadata": {},
   "source": [
    "## 5. Inference with New Texts: Writing Our Own Stories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8989be-d794-4a16-8e2b-a189ac8a23bd",
   "metadata": {},
   "source": [
    "We can write our own stories, but always using the words in the vocabulary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "23f89f56-e517-4eeb-b710-7c65114e32a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8a8b51c2-08ee-4fe7-b3b2-e388eb69cb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "78c7b625-0f65-4357-b25e-a56e58fb9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "aabc1274-6ae2-473d-8b99-0f7192009672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "01705b51-c647-45b2-a21e-855338cbf6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "375e6941-1fca-48af-bafb-c52ee7cdee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6ce63399-3a5a-4fbb-8ef8-d4f7c2968cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a6ecd4bc-5fcf-4869-9158-71aef8343efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.99961543\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6659f-7dc7-49d5-9ba8-5d3f807c7d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
